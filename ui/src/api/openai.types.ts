/**
 * The OpenAI Chat Completion Object type definition.
 * COMPLETION API
 * https://platform.openai.com/docs/api-reference/chat/object
 *
 * {
 *   "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
 *   "object": "chat.completion",
 *   "created": 1741570283,
 *   "model": "gpt-4o-2024-08-06",
 *   "choices": [
 *     {
 *       "index": 0,
 *       "message": {
 *         "role": "assistant",
 *         "content": "The image shows a wooden boardwalk path running through a lush green field or meadow. The sky is bright blue with some scattered clouds, giving the scene a serene and peaceful atmosphere. Trees and shrubs are visible in the background.",
 *         "refusal": null,
 *         "annotations": []
 *       },
 *       "logprobs": null,
 *       "finish_reason": "stop"
 *     }
 *   ],
 *   "usage": {
 *     "prompt_tokens": 1117,
 *     "completion_tokens": 46,
 *     "total_tokens": 1163,
 *     "prompt_tokens_details": {
 *       "cached_tokens": 0,
 *       "audio_tokens": 0
 *     },
 *     "completion_tokens_details": {
 *       "reasoning_tokens": 0,
 *       "audio_tokens": 0,
 *       "accepted_prediction_tokens": 0,
 *       "rejected_prediction_tokens": 0
 *     }
 *   },
 *   "service_tier": "default",
 *   "system_fingerprint": "fp_fc9f1d7035"
 * }
 */
export type OpenAiChatCompletionObject = {
    id: string;
    object: string; // chat.completion
    created: number;
    model: string;
    choices: Array<{
        index: number;
        message: {
            role: string;
            content: string;
            refusal?: string | null; // Refusal message generated by the model, if applicable
            annotations?: any[]
        };
        logprobs?: any; // Log probabilities if available
        finish_reason: string | null;
    }>;
    usage?: {
        prompt_tokens: number;
        completion_tokens: number;
        total_tokens: number;
        prompt_tokens_details?: {
            cached_tokens: number;
            audio_tokens: number;
        };
        completion_tokens_details?: {
            reasoning_tokens: number;
            audio_tokens: number;
            accepted_prediction_tokens: number;
            rejected_prediction_tokens: number;
        };
    };
    service_tier?: string; // Optional, if available
    system_fingerprint?: string; // Optional, if available
}

/**
 * The OpenAI Chat Completion List type definition.
 * COMPLETION API
 * https://platform.openai.com/docs/api-reference/chat/list-object
 *
 * {
 *   "object": "list",
 *   "data": [
 *     {
 *       "object": "chat.completion",
 *       "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
 *       "model": "gpt-4o-2024-08-06",
 *       "created": 1738960610,
 *       "request_id": "req_ded8ab984ec4bf840f37566c1011c417",
 *       "tool_choice": null,
 *       "usage": {
 *         "total_tokens": 31,
 *         "completion_tokens": 18,
 *         "prompt_tokens": 13
 *       },
 *       "seed": 4944116822809979520,
 *       "top_p": 1.0,
 *       "temperature": 1.0,
 *       "presence_penalty": 0.0,
 *       "frequency_penalty": 0.0,
 *       "system_fingerprint": "fp_50cad350e4",
 *       "input_user": null,
 *       "service_tier": "default",
 *       "tools": null,
 *       "metadata": {},
 *       "choices": [
 *         {
 *           "index": 0,
 *           "message": {
 *             "content": "Mind of circuits hum,  \nLearning patterns in silenceâ€”  \nFuture's quiet spark.",
 *             "role": "assistant",
 *             "tool_calls": null,
 *             "function_call": null
 *           },
 *           "finish_reason": "stop",
 *           "logprobs": null
 *         }
 *       ],
 *       "response_format": null
 *     }
 *   ],
 *   "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
 *   "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2",
 *   "has_more": false
 * }
 */
export type OpenAiChatCompletionListObject = {
    data: OpenAiChatCompletionObject[];
    object: string; // Always set to "list"
    first_id: string; // ID of the first completion
    last_id: string; // ID of the last completion
    has_more: boolean; // Indicates if there are more completions available
}


/**
 * The OpenAI Chat Completion Message List type definition.
 * COMPLETION API
 * https://platform.openai.com/docs/api-reference/chat/message-list
 *
 * {
 *   "object": "list",
 *   "data": [
 *     {
 *       "id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
 *       "role": "user",
 *       "content": "write a haiku about ai",
 *       "name": null,
 *       "content_parts": null
 *     }
 *   ],
 *   "first_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
 *   "last_id": "chatcmpl-AyPNinnUqUDYo9SAdA52NobMflmj2-0",
 *   "has_more": false
 * }
 */
export type OpenAiChatCompletionMessageListObject = {
    object: string; // Always set to "list"
    data: OpenAiChatCompletionMessageObject[];
    first_id: string; // ID of the first message
    last_id: string; // ID of the last message
    has_more: boolean; // Indicates if there are more messages available
}

export type OpenAiChatCompletionMessageObject = {
    id: string; // Unique identifier for the message
    role: string; // "user", "assistant"
    content: string | null;
    refusal?: string | null;
    content_parts?: {
        type: string; // "text" or "image"
        text?: string | null;
        image_url?: {
            url: string
            detail?: string // Specifies the detail level of the image. Learn more in the Vision guide.
        }
    }[] | null;
    tool_calls?: {
        id: string;
        type: string; // Currently, only function is supported.
        function?: {
            name: string;
            arguments: string; // JSON string of arguments passed to the function
        } | null;
    }[] | null;
    audio?: {
        id: string;f
        data: string; // Base64 encoded audio data
        expires_at?: number;
        transcript?: string;
    }
    annotations?: {
        type: string; // Always set to "url_citation"
        url_citation: {
            url: string;
            title: string;
            start_index: number;
            end_index: number;
        }
    }[];
}

/**
 * The OpenAI Responses Request type definition.
 * RESPONSES API
 * https://platform.openai.com/docs/api-reference/responses/create
 *
 * curl https://api.openai.com/v1/responses \
 *   -H "Content-Type: application/json" \
 *   -H "Authorization: Bearer $OPENAI_API_KEY" \
 *   -d '{
 *     "model": "gpt-4.1",
 *     "input": [
 *       {
 *         "role": "user",
 *         "content": [
 *           {"type": "input_text", "text": "what is in this image?"},
 *           {
 *             "type": "input_image",
 *             "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
 *           }
 *         ]
 *       }
 *     ]
 *   }'
 */
export type OpenAiResponsesRequest = {
    background?: boolean; // Whether to run the response in the background
    model?: string
    input?: string | OpenAiResponsesRequestInput[];
    include?: string[]; // Additional output data to include in the response (coe_interpreter_call.outputs, ...)
    instructions?: string | null; // Instructions for the response
    max_output_tokens?: number | null; // Maximum tokens allowed in the output
    parallel_tool_calls?: boolean; // Whether to allow parallel tool calls
    previous_response_id?: string | null; // ID of the previous response to continue from
    prompt_cache_key?: string; // Cache key for the prompt
    safety_identifier?: string; // Safety identifier for the response
    service_tier?: 'auto' | 'default' | 'flex' | 'priority'; // Service tier for the response
    reasoning?: {
        effort?: string | null; // Effort level for reasoning
        summary?: string | null; // Summary of the reasoning
    };
    store?: boolean; // Whether to store the response
    stream?: boolean; // Whether to stream the response
    temperature?: number | null; // Temperature for response generation
    top_p?: number | null; // Top-p sampling for response generation
    top_logprobs?: number | null; // Number of top log probabilities to return
    truncation?: 'disabled' | 'auto'; // Whether to disable truncation or use automatic truncation
    text?: {
        format?: {
            type: 'text' | 'json_object' | 'json_schema'; // Format of the response text
        }
    };
    tool_choice?: 'auto' | 'none' | 'required' | {
        type: string // file_search, web_search_preview, computer_use_preview, code_interpreter, image_generation, function, mcp
        name?: string; // function and mcp only
        server_label?: string; // mcp only
    }; // Tool choice for the response
    tools?: Array<{
        type: string;
        [key: string]: any; // Additional tool parameters
    }>
}

export type OpenAiResponsesRequestInput = OpenAiResponsesRequestInputMessage
    | OpenAiResponsesRequestInputItem
    | OpenAiResponsesRequestInputItemReference;

export type OpenAiResponsesRequestInputMessage = {
    type?: 'message';
    role: 'user' | 'assistant' | 'system' | 'developer';
    content: string | Array<{
        type: 'input_text' | 'input_image' | 'input_file'
        text?: string; // input_text
        detail?: string; // input_image
        file_id?: string; // input_image, input_file
        image_url?: string; // input_image
        file_url?: string; // input_file
        file_data?: string // input_file
    }>
}

export type OpenAiResponsesRequestInputItem = OpenAiResponsesRequestInputMessage
    | OpenAiResponsesRequestInputFileSearchToolCall
    | OpenAiResponsesRequestInputComputerToolCall
    | OpenAiResponsesRequestInputMCPToolCall
    // @todo define missing types

export type OpenAiResponsesRequestInputFileSearchToolCall = {
    type: 'file_search_call';
    // @todo define this type
}

export type OpenAiResponsesRequestInputComputerToolCall = {
    type: 'computer_call';
    // @todo define this type
}

export type OpenAiResponsesRequestInputMCPToolCall = {
    type: 'mcp_call';
    // @todo define this type
}

export type OpenAiResponsesRequestInputItemReference = {
    id: string; // The ID of the item to reference.
    type: 'item_reference';
}

/**
 * The OpenAI Response Object type definition.
 * RESPONSES API
 * https://platform.openai.com/docs/api-reference/responses/object
 *
 * {
 *   "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
 *   "object": "response",
 *   "created_at": 1741476777,
 *   "status": "completed",
 *   "error": null,
 *   "incomplete_details": null,
 *   "instructions": null,
 *   "max_output_tokens": null,
 *   "model": "gpt-4o-2024-08-06",
 *   "output": [
 *     {
 *       "type": "message",
 *       "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
 *       "status": "completed",
 *       "role": "assistant",
 *       "content": [
 *         {
 *           "type": "output_text",
 *           "text": "The image depicts a scenic landscape with a wooden boardwalk or pathway leading through lush, green grass under a blue sky with some clouds. The setting suggests a peaceful natural area, possibly a park or nature reserve. There are trees and shrubs in the background.",
 *           "annotations": []
 *         }
 *       ]
 *     }
 *   ],
 *   "parallel_tool_calls": true,
 *   "previous_response_id": null,
 *   "reasoning": {
 *     "effort": null,
 *     "summary": null
 *   },
 *   "store": true,
 *   "temperature": 1,
 *   "text": {
 *     "format": {
 *       "type": "text"
 *     }
 *   },
 *   "tool_choice": "auto",
 *   "tools": [],
 *   "top_p": 1,
 *   "truncation": "disabled",
 *   "usage": {
 *     "input_tokens": 328,
 *     "input_tokens_details": {
 *       "cached_tokens": 0
 *     },
 *     "output_tokens": 52,
 *     "output_tokens_details": {
 *       "reasoning_tokens": 0
 *     },
 *     "total_tokens": 380
 *   },
 *   "user": null,
 *   "metadata": {}
 * }
 */
export type OpenAiResponseObject = {
 id : string;
    object: string; // Always set to "response"
    created_at: number; // Unix timestamp
    status: string; // One of completed, failed, in_progress, cancelled, queued, or incomplete
    error?: {
        message?: string;
        code?: string;
    } | null; // Error details if any
    incomplete_details?: any; // Details about incomplete responses, if applicable
    instructions?: string | any[]; // Instructions provided for the response
    max_output_tokens?: number | null; // Maximum tokens allowed in the output
    model: string; // Model used for the response
    output: Array<OpenAiResponseOutput>;
    output_text?: string;
    parallel_tool_calls?: boolean;
    previous_response_id?: string | null;
    prompt?: any | null;
    prompt_cache_key?: string
    reasoning?: {
        effort?: string | null;
        summary?: string | null;
    };
    safety_identifier?: string;
    service_tier?: string; // auto, default, flex, priority
    temperature?: number | null;
    text?: any;
    tool_choice?: string | any;
    tools?: any[];
    top_logprobs?: any; // Log probabilities if available
    top_p?: number | null;
    truncation?: string; // disabled, auto
    usage?: {
        input_tokens: number;
        input_tokens_details?: {
            cached_tokens: number; // Number of tokens cached
        };
        output_tokens: number;
        output_tokens_details?: {
            reasoning_tokens?: number; // Number of reasoning tokens used
        };
        total_tokens: number; // Total tokens used in the request
    };
    user?: string | null; // DEPRECATED! Use safety_identifier and prompt_cache_key instead
}

export type OpenAiResponseOutput = OpenAiResponseOutputMessage
    | OpenAiResponseOutputFileSearchToolCall
    | OpenAiResponseOutputFunctionToolCall
    | OpenAiResponseOutputWebSearchToolCall
    | OpenAiResponseOutputComputerToolCall
    | OpenAiResponseOutputReasoning
    | OpenAiResponseOutputImageGeneration
    | OpenAiResponseOutputCodeInterpreterToolCall
    | OpenAiResponseOutputLocalShellCall
    | OpenAiResponseOutputMCPToolCall
    | OpenAiResponseOutputMCPListTools
    | OpenAiResponseOutputMCPApprovalRequest;


export type OpenAiResponseOutputMessage = {
    type: 'message'; // Always "message"
    id: string;
    status: string;
    role: string;
    content: Array<{
        type: string; // "output_text", "refusal"
        text?: string;
        annotations?: any[];
        refusal?: string;
    }>;
}

export type OpenAiResponseOutputFileSearchToolCall = {
    type: 'file_search_call', // "file_search_call"
    id: string,
    queries: string[],
    status: string, // One of in_progress, searching, incomplete or failed,
    results: null | Array<{
        file_id: string,
        filename: string,
        score: number,
        text: string,
        attributes?: any
    }>
}

export type OpenAiResponseOutputFunctionToolCall = {
    type: 'function_call'; // Always "function_call"
    id: string; // The unique ID of the function tool call.
    call_id: string; // The unique ID of the function tool call generated by the model.
    name: string; // Function name
    arguments: string; // JSON string of arguments passed to the function
    status: string; // One of in_progress, completed, or incomplete
}

export type OpenAiResponseOutputWebSearchToolCall = {
    type: 'web_search_call';
    id: string;
    status: string;
    action: {
        type: 'search' | 'open_page' | 'find';
        query?: string // for search
        url?: string // for open_page and find
        pattern?: string // for find
    }
}

export type OpenAiResponseOutputComputerToolCall = {
    type: 'computer_call';
    id: string;
    call_id: string;
    status: string;
    action: any // @todo define this type
    pending_safety_checks?: []
}

export type OpenAiResponseOutputReasoning = {
    type: 'reasoning';
    id: string;
    summary: Array<{
        type: 'summary_text'
        text: string;
    }>
    status: string;
    encrypted_content?: string | null; // The encrypted content of the reasoning item - populated when a response is generated with reasoning.encrypted_content in the include parameter.
}

export type OpenAiResponseOutputImageGeneration = {
    type: 'image_generation_call';
    id: string;
    status: string;
    result: string | null // Base64 encoded image data or null if not available
}

export type OpenAiResponseOutputCodeInterpreterToolCall = {
    type: 'image_generation_call';
    id: string;
    status: string;
    code: string | null;
    container_id?: string // The ID of the container where the code was executed
    outputs: null | Array<{
        type: 'logs' | 'image'
        logs?: string // for logs
        url?: string // for image
    }>
}

export type OpenAiResponseOutputLocalShellCall = {
    type: 'local_shell_call';
    id: string;
    call_id: string;
    status: string;
    action: {
        command: string[];
        env: any;
        type: 'exec';
        timeout_ms?: number | null;
        user?: string | null;
        working_directory?: string | null;
    }
}

export type OpenAiResponseOutputMCPToolCall = {
    type: 'mcp_call';
    id: string;
    server_label: string;
    name: string; // Tool name
    arguments: string; // JSON string of arguments passed to the tool
    error?: string | null; // Error message if any
    output?: string | null; // Output of the tool call, if any
}

export type OpenAiResponseOutputMCPListTools = {
    type: 'mcp_list_tools';
    id: string;
    server_label: string;
    error?: string | null; // Error message if any
    tools: Array<{
        name: string;
        description?: string | null;
        input_schema?: any; // JSON schema for the input arguments
        annotations?: any | null; // Additional annotations or metadata about the tool
    }>
}

export type OpenAiResponseOutputMCPApprovalRequest = {
    type: 'mcp_approval_request';
    id: string; // Unique identifier for the MCP approval request
    server_label: string; // MCP server label
    name: string; // Tool name
    arguments: string; // JSON string of arguments passed to the tool
}
